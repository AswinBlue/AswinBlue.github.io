<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.87.0" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>Tensorflow&nbsp;&ndash;&nbsp;AsWindBlew</title><link rel="stylesheet" href="/css/core.min.df05809cfa75ea0a430dc942a79e54236823f6be194b5bc34f0c64744ba5a1b55f91020ad551b34b8af7f2ebee758cc8.css" integrity="sha384-3wWAnPp16gpDDclCp55UI2gj9r4ZS1vDTwxkdEulobVfkQIK1VGzS4r38uvudYzI"><meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Tensorflow" /><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2984318617287323"
     crossorigin="anonymous"></script>
<body><section id="header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/"><span class="site name">AsWindBlew</span></a></span>
        <span class="header right-side"><div class="nav wrap"><nav class="nav"><a class="nav item" href="/categories/">Categories</a><a class="nav item" href="/tags/">Tags</a><a class="nav item" href="/about/">About</a><a class="nav item" href="https://gohugo%2eio/"target="_blank">Hugo</a></nav></div></span></div><div class="site slogan"><span class="title">published by AswinBlue</span></div></section><section id="content"><div class="article-container"><section class="article header">
    <h1 class="article title">Tensorflow</h1><p class="article date">Nov 27, 2021<span class="reading-time"> • 26 minutes to read</span></p></section><article class="article markdown-body"><p>#Tensorflow</p>
<ul>
<li>TensorFlow는 구글에서 수치연산을 위해 만든 라이브러리이다.</li>
</ul>
<h2 id="기본-개념">기본 개념</h2>
<ul>
<li>node와 edge로 구성된 graph를 이용해 수치 연산을 수행한다.
<ul>
<li>node들은 특정한 데이터가 들어오면 연산을 수행하거나, 형태를 변경하거나, 결과를 출력하는 역할을 한다.</li>
<li>edge는 학습데이터가 저장되는 다차원 배열이다.</li>
<li>edge는 node에서 계산된 데이터를 다음 node로 이동시킨다.</li>
<li>edge는 방향성이 있으며(directed), tensor라 불린다.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="설치">설치</h2>
<ol>
<li>python과 pip를 설치한다.</li>
<li><code>pip install tensorflow</code> 명령을 수행한다.</li>
</ol>
<ul>
<li>window에서 &lsquo;client_load_reporting_filter.h&rsquo; 파일을 찾지 못해 설치를 못했다면, path 경로가 너무 길어서 발생하는 오류이다.</li>
<li>실행에서 <code>regedit</code>을 실행하고, &lsquo;HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\FileSystem&rsquo; 레지스트리를 찾아 값을 1로 세팅해준다.</li>
</ul>
<h3 id="연관-모듈">연관 모듈</h3>
<ul>
<li>함께 쓰면 효율이 좋은 모듈들</li>
</ul>
<ol>
<li>matplotlib</li>
<li>numpy</li>
</ol>
<ul>
<li><code>data = np.loadtxt(FILE_NAME, delimiter=',')</code> : ,를 기준으로 데이터를 나누는 csv 파일을 읽어들임. 숫자 데이터를 읽을 때 사용</li>
</ul>
<ol>
<li>keras (tensorflow 설치시 자동성치된다)
<code>y_encoded = to_categorical(y_data)</code> : y_data 를 one-hot-encoding 하는 함수  (tensorflow.keras.utils.to_categorical)</li>
<li>pandas</li>
</ol>
<ul>
<li><code>df = pd.read_csv(FILE_NAME)</code> : csv 파일을 읽어서 dataframe을 구성한다. 숫자 및 문자열 데이터를 읽을 때 사용 가능</li>
</ul>
<ol>
<li>sklearn</li>
</ol>
<ul>
<li>데이터 전처리</li>
</ul>
<pre><code>e = sklearn.preprocessing.LabelEncoder()
e.fit(data)  # data 에 들어있는 값 중 unique한 값을 뽑아(중복 제거) 특정 string에 번호를 매기는(indexing) 함수
data = e.transform(data)  # indexing 된 정보를 바탕으로 실제 data값을 index로 치환
</code></pre><hr>
<h2 id="기본-문법">기본 문법</h2>
<ol>
<li>상수 선언<br>
<code>val = tf.constant(value, dtype=None, shape=None, name='Conts', verify_shape=False)</code></li>
</ol>
<ul>
<li>value = 값</li>
<li>dtype : 데이터 타입, ex) &lsquo;tf.float32&rsquo;, &lsquo;tf.float64&rsquo;, &lsquo;tf.int8&rsquo;
<ul>
<li>float(32, 64), int(8, 16, 64),uint(8, 16), string, bool, complex(64, 128 : 복소수)</li>
</ul>
</li>
<li>shape : 차원, value 형태에 따라 자동으로 설정 됨, ex) &lsquo;[3,3]&rsquo;</li>
<li>name : 상수의 이름</li>
<li>verify_shape : tensor의 shape를 바꿀수 있는지 여부</li>
</ul>
<ol>
<li>배열 생성</li>
</ol>
<ul>
<li><code>arr = tf.range(5)</code></li>
</ul>
<blockquote>
<p>output : <code>tf.Tensor : shape(5,), dtype=int32, numpy=([0, 1, 2, 3, 4], dtype=int32)</code></p>
</blockquote>
<ul>
<li>&lsquo;tf.zeros([2,3])&rsquo;</li>
</ul>
<blockquote>
<p>output : <code>[[0, 0, 0], [0, 0, 0]]</code></p>
</blockquote>
<ul>
<li>&lsquo;tf.ones([2,3])&rsquo;</li>
</ul>
<blockquote>
<p>output : <code>[[1, 1, 1], [1, 1, 1]]</code></p>
</blockquote>
<ul>
<li>&lsquo;tf.fill([2,3], 5)&rsquo;</li>
</ul>
<blockquote>
<p>output : <code>[[5, 5, 5], [5, 5, 5]]</code></p>
</blockquote>
<ol>
<li>연산자
<code>tf.add(x,y)</code> : x + y<br>
<code>tf.subtract(x,y)</code> : x - y<br>
<code>tf.multiply(x,y)</code> : x * y<br>
<code>tf.div(x,y)</code> : x / y<br>
<code>tf.floordiv(x,y)</code> : x // y<br>
<code>tf.mod(x,y)</code> : x % y<br>
<code>tf.pow(x,y)</code> : x ** y<br>
<code>tf.less(x,y)</code> : x &lt; y<br>
<code>tf.less_equal(x,y)</code> : x &lt;= y<br>
<code>tf.greater(x,y)</code> : x &gt; y<br>
<code>tf.greater_equal(x,y)</code> : x &gt;= y<br>
<code>tf.logical_and(x,y)</code> : x &amp; y<br>
<code>tf.logical_or(x,y)</code> : x | y<br>
<code>tf.logical_xor(x,y)</code> : x ^ y<br>
<code>tf.maximum(x,y)</code> : max(x,y)<br>
<code>tf.reduce_sum(a)</code> : 배열 a에서 같은 index 위치의 값을 모두 더한 스칼라 값을 반환<br>
<code>tf.reduce_mean(a)</code> : 배열 a에서 같은 index 위치의 값을 평균낸 스칼라 값을 반환</li>
</ol>
<ul>
<li>x,y가 배열인 경우, 연산자는 같은 index에 위치한 값끼리 연산한다.<br>
ex) <code>tf.add(x,y) = [(x[0] + y[0]), (x[1] + y[1]), (x[2] + y[2]), ...]</code></li>
<li>&lsquo;reduce&rsquo; 가 들어간 연산은 axis 파라미터를 설정하여 어느 축을 기준으로 연산을 수행할지 설정 가능<br>
ex)</li>
</ul>
<pre><code>a = [[1,2,3],[4,5,6]]
tf.reduce_sum(a, axis=0) = [5, 7, 9]
tf.reduce_sum(a, axis=1) = [6, 15]
</code></pre><ol>
<li>변수</li>
</ol>
<ul>
<li>
<p>tensorflow에서 변수는 node를 만들고, 그 안의 값을 참조하는 방식이다.</p>
<p><code>var = tf.Variable(value, dtype=type)</code></p>
<ul>
<li>value : 변수에 담을 값</li>
<li>dtype : 변수 타입</li>
<li>2.x 버전에서는 위와같이 선언과 동시에 초기화가 가능하다.</li>
</ul>
</li>
<li>
<p>node를 생성하고 var은 그 node의 주소를 가리킨다.</p>
<p><code>var.assign(value)</code></p>
</li>
<li>
<p>var이 가리키는 node에 value 값을 적용</p>
<p><code>var.assign_add(value)</code></p>
</li>
<li>
<p>var이 가리키는 node에 value 값을 더함</p>
<p><code>var.assign_add(value)</code></p>
</li>
<li>
<p>var이 가리키는 node에 value 값을 뺌</p>
<p><code>tf.cast()</code></p>
</li>
<li>
<p>변수를 특정 값, 특정 형태로 치환해주는 함수</p>
</li>
</ul>
<ol>
<li>
<p>출력<br>
<code>val.numpy()</code> : &lsquo;val&rsquo; tensor를 numpy 배열 형태로 출력</p>
</li>
<li>
<p>비교
<code>tf.equal()</code> : tensorflow 변수를 비교하는 함수</p>
</li>
<li>
<p>랜덤
<code>tf.random.set_seed()</code> : 정수를 이용해 랜덤값 시드 설정
<code>tf.random.normal([2, 1], mean=0.0))</code> : 정규분포에 기반한 랜덤값, 인자로 행렬 shape와 평균이 들어간다.</p>
</li>
</ol>
<hr>
<h2 id="심화-내용">심화 내용</h2>
<h3 id="tensorflow와-행렬">tensorflow와 행렬</h3>
<ul>
<li>TensorFlow에서 배열은 행렬로 표현되며, 행렬은 shape라 불린다.</li>
<li>행렬 계산을 위한 함수를 제공한다.
<code>tf.matmul(a, b)</code> : 행렬의 내적(곱)
<code>tf.linalg.inv(a)</code> : 역행렬</li>
</ul>
<ol>
<li>Broadcasting</li>
</ol>
<ul>
<li>행렬을 곱셈 혹은 덧셈을 하기 위해서는 shape에 대한 제약조건이 있고, tensorflow에서도 마찬가지다.</li>
<li>tensorflow에서는 행렬 연산에서 차원(shape)이 맞지 않을 때 행렬을 자동으로 늘려서(Stretch) 차원을 맞춰주는 Broadcasting기능이 있다.
<ul>
<li>연산시 shape는 첫번째 피연산자를 기준으로 한다.</li>
<li>stretch 시 새로 생성된 공간에는 기존 내용을 복사하여 채워넣는다.</li>
<li>단, 늘릴 수는 있지만, 줄일수는 없다.
ex)
a[4,3] + b[1,3] : 가능
a[4,3] + b[1,5] : 불가능 (3 &lt; 5 이므로, 5를 3으로 바꾸려면 축소해야함)
a[4,1] + b[1,3] : 가능</li>
</ul>
</li>
</ul>
<h3 id="tensorflow-함수">tensorflow 함수</h3>
<ul>
<li>tensorflow 1.x 버전은 placeholder를 통해 입력을 받는 객체를 생성하고, 실행시 session을 통해 feed 값을 전달한다. 즉 명시적으로 입력 형태를 구성해야 했다.</li>
<li>tensorflow는 2.x 버전부터 python 프로그램처럼 라이브러리를 사용할 수 있도록 연산에 함수를 제공하고 있다. 함수를 사용하면 placeholder를 생략하고 사용할 수 있다.</li>
<li>tensorflow 함수는 파이썬 함수처럼 정의하여 사용 가능하며, 컴파일시 속도 향상을 원한다면 <code>@tf.function</code> 데코레이터를 적용하면 된다.<br>
ex)</li>
</ul>
<pre><code>@tf.function
def t_func(a,b):
    return tf.matmul(a,b)

x = [[4,5,6],[6,7,8]]  # tensorflow 변수가 아님
w = tf.Variable([2,5],[6,5],[17,10])
print(t_func(x,w))
# tensorflow 2.x 이후부터는 변수 x같은 값들도
# placeholder를 만들고 feed 값을 주는 복잡한 과정 없이
# tensorflow 함수를 이용해 연산 가능해졌다.
</code></pre><h3 id="tensorflow-미분">tensorflow 미분</h3>
<ul>
<li>gradient 계산에 미분이 많이 사용고, tensorflow는 미분 함수를 제공한다.</li>
<li><code>tape.gradient(y,x)</code> : 텐서 x에 대한 y의 미분값</li>
<li><code>tape.watch()</code> : 상수형 텐서를 변수형 텐서로 변환</li>
</ul>
<p>ex)</p>
<pre><code>x1 = tf.Variable(tf.constant(1.0))  # 변수 선언
x2 = tf.Variable(tf.constant(2.0))  # 변수 선언
with tf.GradientTape() as tape:  # 미분을 위해 GradientTape 객체 생성
    y = tf.multiply(x1, x2)  # 미분할 함수값을 GradientTape 객체 안에서 정의
gradients = tape.gradient(y, [x1, x2])  # x1 미분값과 x2 미분값을 각각 반환
# y = x1 * x2
# x1 에 대한 미분값 : 2.0
# x2 에 대한 미분값 : 1.0
# gradients = [2.0, 1.0]

a = tf.constant(2.0)
gradients2 = tape.gradient(y,a)
# 상수로 미분하면 None 값이 된다.
# gradients2 = None

# 상수를 변수로 변환시켜 미분시킬 수 있다.
with tf.GradientTape() as tape:
    tape.watch(a)
    y = tf.multiply(x1, a)
gradients3 = tape.gradient(y,a)
# gradients3 = 1.0
</code></pre><h3 id="선형-회귀">선형 회귀</h3>
<ul>
<li>&lsquo;딥러닝&rsquo;은 데이터를 통해 관계를 학습하고, 학습된 모델을 통해 데이터가 주어지면 예측값을 도출해 내는 기술이다.</li>
<li>&lsquo;딥러닝&rsquo;의 가장 기본적인 계산 원리는 &lsquo;션형 회귀&rsquo;와 &lsquo;로지스틱 회귀&rsquo; 이다.</li>
</ul>
<ol>
<li>선형회귀 : 데이터 분포를 통해 데이터들과 가장 근접한 선을 도출해내는 계산법</li>
<li>로지스틱 회귀 : 0과 1 둘 중 하나를 선택하는 계산법</li>
</ol>
<ul>
<li>판단의 근거를 마련할 때 사용</li>
<li>sigmoid 함수를 사용하여 확률값으로 사용</li>
</ul>
<h4 id="선형-회귀-정의">선형 회귀 정의</h4>
<ul>
<li>
<p>종속변수 y와 한개 이상의 독립변수 x와의 선형 상관관계를 모델링하는 회귀분석 기법</p>
<ul>
<li>단순 선형회귀 : 하나의 변수에 기반하여 동작</li>
<li>다중 선형 회귀 : 둘 이상의 변수에 기반하여 동작</li>
</ul>
</li>
<li>
<p>선형 예측함수를 통해 회귀식을 모델링하고, 알려지지 않은 파라미터를 데이터로 추정</p>
</li>
<li>
<p>회귀식을 선형 모델이라고 한다.</p>
</li>
<li>
<p>값을 예측하기 위해 학습 데이터로 적합한 예측 모형을 개발한다.</p>
</li>
<li>
<p>종속변수 y와 이에 연관된 독립변수들 x1, x2&hellip; 에 대해 x와 y간의 관계를 정량화 할 수 있다.</p>
</li>
<li>
<p>일반적으로 최소제곱을 사용해 선형 회귀 모델을 구할 수 있다. (y = ax + b 형태)</p>
<ul>
<li>독립변수(x)가 증가하면 최소 제곱법으로 처리가 불가능하다.</li>
</ul>
</li>
<li>
<p>딥러닝에서는 y = wx + b 형태로 표현하는데, w 는 weight, b는 bias 를 뜻한다.</p>
<ul>
<li>weight : 가중치, 입력값 x의 영향도를 표현하는 상수</li>
<li>bias : 기준점, 판단의 근거가 되는 식의 기준점을 표현하는 상수</li>
</ul>
</li>
</ul>
<h4 id="오차방정식">오차방정식</h4>
<ul>
<li>
<p>선형 회귀에서 입력값이 여러개일 경우, 첫번째 입력으로 임의의 선을 그린다.</p>
</li>
<li>
<p>정답과 임의의 선이 맞는지 확인하고 평가한다 (오차 확인)</p>
</li>
<li>
<p>확인된 오차 값을 이용해 임의의 선을 수정한다.</p>
</li>
<li>
<p>즉,  y = ax + b 에서 (x,y)를 입력으로 받고 a,b를 추론한다. 이러한 계산 식을 오차방정식이라 한다.</p>
</li>
<li>
<p>오차의 합 = ∑ (예측값 - 정답)²</p>
</li>
<li>
<p>MSE : Mean Squared Error, 평균제곱오차 = (오차의 합) / n</p>
</li>
<li>
<p>RMSE : Root Mean Squared Error, 평균 제곱근 오차 = root(편균제곱오차)</p>
</li>
</ul>
<h4 id="경사-하강법">경사 하강법</h4>
<ul>
<li>
<p>대표적인 &lsquo;최적화 알고리즘&rsquo;으로, 비용 함수를 최소화하기 위해 반복해서 파라미터를 조정해나가는 방식이다.</p>
</li>
<li>
<p><code>y = a*x</code> 방정식에서 x = [1,2,3] y = [1,2,3] 이라고 한다면 a값은 1이다.
이때 MSE 오차식과 x에 대해 그래프를 그리면 2차원 그래프가 나오게 된다. 이때 기울기가 0인 부분, 즉 꼭짓점의 x 값이 정답이 된다.</p>
</li>
<li>
<p>이러한 특성을 이용하여 다음과 같이 정답을 찾는 recursive한 전략을 취할 수 있다.</p>
<ol>
<li>임의의 값 x1에서 미분을 구한다.</li>
<li>구해진 기울기의 반대 방향으로 이동하여 그래프와 겹쳐지는 부분의 x좌표를 x2라 한다.</li>
<li>1~2 과정을 반복하면 점차 기울기가 줄어들고, 이를 충분히 수행하면 정답값에 수렴한다.</li>
</ol>
</li>
<li>
<p>하지만 오차 그래프의 폭이 좁은 경우, 위 방식을 수행하면 특정 값으로 수렴하지 않고 결과값이 발산한다.</p>
</li>
<li>
<p>이를 막기 위해 기울기를 100% 취하지 않고, &lsquo;학습률&rsquo; 이라는 상수를 곱해 일정 양만큼만 전략에 반영될 수 있게 한다.</p>
</li>
<li>
<p>학습률은 정해진 값이 아니고, 데이터에 따라 적합한 값이 달라지는 상수이다.</p>
</li>
<li>
<p>위 전략을 수정하여 다시 적용하면</p>
</li>
</ul>
<ol>
<li>임의의 값 x1에서 미분을 구하고, 학습률을 적용하여 값을 조정한다.</li>
<li>구해진 값을 기울기로하여 이동할 때 그래프와 겹쳐지는 부분의 x좌표를 x2라 한다.</li>
<li>1~2 과정을 반복하면 점차 기울기가 줄어들고, 이를 충분히 수행하면 정답값에 수렴한다.</li>
</ol>
<pre><code>learning_rate = 0.1
with tf.GradleTape() as tape:
  hypothesis = W * x_data
  cost = tf.reduce_mean(tf.square)
</code></pre><hr>
<h3 id="로지스틱-회귀">로지스틱 회귀</h3>
<ul>
<li>
<p>선형회귀와 함께 대표적인 딥러닝 알고리즘이다.</p>
</li>
<li>
<p>독립변수의 선형 결합을 이용하여 사건 발생의 가능성을 예측하는데 사용되는 &lsquo;통계 기법&rsquo; 이다. (확률 계산)</p>
</li>
<li>
<p>로지스틱 회귀는 종속변수와 독립변수 간의 관계를 함수로 나타내어 향후 예측모델에서 사용하므로, 독립변수의 선형 결합으 종속변수를 설명한다는 관점에서 선형 회귀분석과 유사하다.</p>
</li>
<li>
<p>하지만, 로지스틱 회귀는 데이터의 결과가 특정 분류로 나뉘어 지기 때문에 classification 기법으로 볼 수 있다.</p>
</li>
<li>
<p>이진 분류 문제, 즉 0과 1 중 하나를 판별하는 문제는 로지스틱 회귀를 이용하여 풀 수 있다.</p>
</li>
<li>
<p>step function 혹은 sigmoid를 사용하는데, 보통 0과 1 사이의 확률값을 표현할 수 있는 sigmoid를 사용한다.</p>
</li>
</ul>
<h4 id="시그모이드">시그모이드</h4>
<ul>
<li>
<p>시그모이드 방정식은 아래와 같다.<br>
<code>y = 1 / (1 + e &lt;sup&gt;-x&lt;/sup&gt;)</code></p>
</li>
<li>
<p>e는 자연상수이며, 자연상수를 사용하였기 때문에 확률값으로 사용 가능하다.</p>
</li>
<li>
<p>sigmoid 함수에 선형 회귀 함수를 대입하면 아래와 같이 된다.<br>
<code>y = 1 / (1 + e &lt;sup&gt;(-wx+b)&lt;/sup&gt;)</code></p>
</li>
<li>
<p>이 함수에 경사하강법을 이용하여 w와 b를 찾아낼 수 있다.</p>
</li>
<li>
<p>w값이 증가하면 sigmoid 함수는 step function에 유사하게 경사가 가팔라 진다.</p>
</li>
<li>
<p>b값이 증가하면 그래프가 우측 방향으로 이동한다.</p>
</li>
</ul>
<h4 id="오차함수">오차함수</h4>
<ul>
<li>
<p>로지스틱 회귀는 target이 0 또는 1 두가지라는 점에서 선형 회귀와 다르다.</p>
</li>
<li>
<p>때문에 로지스틱 회귀는 오차함수도 두가지가 있다.</p>
<ul>
<li>정답이 0일 경우 -log(l-h) 그래프 형태이다.</li>
<li>정답이 1일 경우 -log(h) 그래프 형태이다.</li>
</ul>
</li>
<li>
<p>정답값 0 혹은 1을 대입하면 원하는 오차함수가 나오는 식을 binary cross entropy 라 하고, 그 식은 다음과 같다.<br>
<code>Y = -(Y * LOG(H) + (1-Y)*LOG(1-H))</code></p>
</li>
<li>
<p>로지스틱 회귀법을 tensorflow 함수로 구현하면 아래와 같다.</p>
</li>
</ul>
<pre><code># 6 by 2 형태의 x 데이터 학습값
x_train = np.array([[1., 1.],
                   [1., 2.],
                   [2., 1.],
                   [3., 2.],
                   [3., 3.],
                   [2., 3.]],
                   dtype=np.float32)
# 6 by 1 형태의 y 데이터 학습값
y_train = np.array([[0.],
                   [0.],
                   [0.],
                   [1.],
                   [1.],
                   [1.]],
                   dtype=np.float32)

# 이 학습값을 이용해 W와 b를 찾아본다.


# 랜덤값을 위한 설정
tf.random.set_seed(12345)
# W와 b의 초기값을 랜덤하게 설정, x값이 [6, 2] 이므로 W 형태를 [2, 1] 로 해야 y 값인 [6, 1] 에 맞게 matmul이 가능하다.
W = tf.Variable(tf.random.normal([2, 1], mean=0.0))
b = tf.Variable(tf.random.normal([1], mean=0.0))

print('weights: \n', W.numpy(), '\n\nbias: \n', b.numpy())

# x값을 sigmoid 함수에 대입하여 y값을 반환하는 함수
# x값의 shape가 [,2] 형태이므로 z = -(w1*x1 + w2*x2 + b) 가 된다.
def predict(X):
    z = tf.matmul(X, W) + b
    hypothesis = 1 / (1 + tf.exp(-z))
    return hypothesis

# 반복 학습
for i in range(2001):
    with tf.GradientTape() as tape:
        hypothesis = predict(x_train)
        # cost : binary cross entropy 식으로 loss 값을 계산
        cost = tf.reduce_mean(-tf.reduce_sum(y_train*tf.math.log(hypothesis) + (1-y_train)*tf.math.log(1-hypothesis)))

        # w와 b로 편미분하여 오차값 계산
        W_grad, b_grad = tape.gradient(cost, [W, b])

        # 오차값에 learning rate를 적용한 결과값으로 w와 b를 재설정
        W.assign_sub(learning_rate * W_grad)
        b.assign_sub(learning_rate * b_grad)

# 계산된 w,b를 사용하여 x, y에 대해 정상적으로 예측값이 나오는지 확인
def acc(hypo, label):
    # 0.5 이상이면 0, 이하이면 1의 확률이 더 높으므로, 0.5를 기준으로 0 또는 1로 치환해 준다.
    predicted = tf.cast(hypo &gt; 0.5, dtype=tf.float32)
    # 정확도 = 계산값과 정답을 비교하여 맞으면 1점, 틀리면 0점으로 판단한 후 전체 점수를 평균 낸 값
    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, label), dtype=tf.float32))
    return accuracy

# 결과 계산
accuracy = acc(predict(x_train), y_train).numpy()
</code></pre><hr>
<h3 id="퍼셉트론">퍼셉트론</h3>
<ul>
<li>퍼셉트론은 뉴럴 네트워크의 기본이 되는 개념으로, 인간의 신경망을 본따 프랑크 로젠블라트가 1957년에 고안한 알고리즘이다.</li>
<li>인간의 신경망은 외부 자극을 입력으로 받아 뉴런을 타고 신호가 전달된다. 뉴런과 뉴런 사이의 시냅스에서 신호를 전달하려면 역치값을 넘겨야 신호가 전달된다.</li>
<li>퍼셉트론은 입력을 받아 가중합(w1<em>x1 + w2+x2 + &hellip; + wi</em>xi+ b)을 취하고, 활성화 함수(sigmoid)를 거쳐 출력값을 생성한다.</li>
</ul>
<h4 id="다층-퍼셉트론">다층 퍼셉트론</h4>
<ul>
<li>
<p>한 개의 퍼셉트론은 여러 문제를 해결할수 있다.</p>
<ul>
<li>좌표 평면에서 선 하나로 그룹을 구분지을 수 있는 경우에 해당한다.</li>
<li>대표적인 모델로는 AND모델, OR 모델이 있다.</li>
</ul>
</li>
<li>
<p>하지만 단일 퍼셉트론으로 풀지 못하는 문제도 존재한다.</p>
<ul>
<li>XOR 모델이 대표적이다. 선 하나를 그어서 그룹을 분류할 수 없다.</li>
</ul>
</li>
<li>
<p>XOR 모델은 OR 퍼셉트론과 NAND 퍼셉트론을 1차적으로 수행하고, 두 수행에 대한 결과를 AND 연산하면 구할 수 있다. 이를 그래프로 표현하면 아래와 같다.</p>
</li>
</ul>
<pre><code>0층     1층     2층
x1   →   s1  ↘  
   ↘ ↗         y
   ↗ ↘         
x2   →   s2  ↗  
</code></pre><ul>
<li>다중 퍼셉트론은 여러 layer를 두고 연산을 한다는 의미이며, layer가 증가하면 더 많이 분석된다는 뜻.</li>
<li>0층(가장 처음)은 input layer, 2층(가장 마지막)은 output layer, 그 사이의 layer는 hidden layer라 칭한다.</li>
<li>hidden layer를 많이 만들면 대체로 데이터를 많이 분석하여 더 좋은 결과를 낼 수 있다고 할 수 있다.</li>
</ul>
<h3 id="오차-역전파">오차 역전파</h3>
<ul>
<li>
<p>은닉층에 있는 각각의 w와 b를 구하는 방법이다.</p>
</li>
<li>
<p>다층 퍼셉트론을 구성하면 각 layer마다 w와 b값이 구성되는데, 이때 오차를 구하기 위해 미분값을 구하는 것이 쉽지 않다.</p>
<ul>
<li>미분 안에 연결된 식이 많기 때문</li>
<li>layer의 개수는 변동될 수 있기 때문에 계산이 복잡하다</li>
</ul>
</li>
<li>
<p>이 문제를 해결하기 위해 1980년도 오차 역전파 알고리즘이 발명된다. 이전에도 w와 b를 구할수는 있었지만, 구하는 방법에 대해 규칙성을 찾지는 못했다.</p>
</li>
</ul>
<h4 id="오차-역전파-개요">오차 역전파 개요</h4>
<ul>
<li>최적화의 계산 방향이 output layer 에서 input layer 방향으로 진행된다. 이 떄문에 이 알고리즘을 back propagation 이라 부른다.</li>
<li>퍼셉트론에서 w와 b값을 찾기 위해 오차가 작아지는 방향으로(기울기가 0이 되는 방향으로) 업데이트 해 나갔는데, 다층 퍼셉트론에서는 다음 식으로 가중치를 변화시켜 나간다.
<ul>
<li><code>W(t+1) = W * t - (∂오차) / (∂w)</code>: 새 가중치는 현 가중치에서 가중치에 대한 기울기를 뺀 값</li>
</ul>
</li>
</ul>
<h4 id="출력층-오차">출력층 오차</h4>
<ul>
<li>다층 퍼셉트론의 각 노드는 (1)입력값을 이용해 가중합을 만들고, (2) 가중합을 활성화 함수를 적용해 출력하는 두 단계를 수행한다.</li>
<li>3개 layer를 가지는 형태를 표현하면 아래와 같다.
<ul>
<li>yh1, yh2 : hidden layer의 출력값</li>
<li>y_out1, y_out2 : output layer의 출력값, 예측값</li>
</ul>
</li>
</ul>
<pre><code>0층               1층                                       2층
x1 (w11)→ [가중합1 -&gt; 활성화함수1]  →    yh1 (w31)→ [가중합3 -&gt; 활성화함수3]  → y_out1
 (w21)↘  ↗                              (w41)↘  ↗
 (w12)↗  ↘                              (w32)↗  ↘
x2 (w22)→ [가중합2 -&gt; 활성화함수2]  →    yh2 (w42) → [가중합4 -&gt; 활성화함수4]  → y_out2
</code></pre><ul>
<li>
<p>오차 역전파는 y_out 값에서 반대로 진행하여 가중치 w를 업데이트 한다.</p>
</li>
<li>
<p><code>w31(t+1) = w31 * t - (∂오차 y_out)/(∂w31)</code> : 현재 weight에 미분값을 빼주면 다음 weight가 된다.</p>
</li>
<li>
<p>오차 y_out 안에는 여러개의 출력값이 존재할 수 있다. (output layer의 node 개수만큼)</p>
</li>
<li>
<p>y_out 안의 각각의 예측값에 대한 오차는 MSE를 이용해 구한다.</p>
<ul>
<li>output layer의 node가 n개라고 하면, k번째 오차는 다음과 같다. <code>오차_y_out_k = (y_target_k - y_out_k)² / n</code></li>
</ul>
</li>
<li>
<p>오차 역전파로, y_out1 값의 오차로 w31을 업데이트 해 보자.</p>
</li>
</ul>
<ol>
<li>
<p>오차의 값은 <code>∂오차y_out / ∂w31</code> 이다.</p>
</li>
<li>
<p>chain rule에 의해 <code>∂오차y_out / ∂w31 = (∂오차y_out / ∂y_out1) * (∂y_out1 / ∂가중합3) * (∂가중합3 / ∂w31)</code> 가 성립한다. 이 식의 우항을 각각 나누어 계산하여 보자.
2-1) <code>(∂오차y_out / ∂y_out1)</code>을 y_out1에 의해 편미분을 하면 y_out1과 관계없는 y_out2는 상수가 되어 사라진다. <code>y_out = y_out1 + y_out2 = (y_target1 - y_out1)² / 2 + (y_target2 - y_out2)² / 2</code> 이기때문에 최종 식은 <code>(∂오차y_out / ∂y_out1) = 1/2 * ∂(y_target1 - y_out1)² / ∂y_out1 = y_out1 - y_target1</code> 가 된다.
2-2) <code>(∂y_out1 / ∂가중합3)</code> 은 &lsquo;활성화함수3&rsquo;을 미분 해 주는것과 같다.<br>
우리는 활성함수로 시그모이드를 사용했고, 시그모이드의 미분은 <code>∂σ(x) / ∂x = σ(x) * (1 - σ(x))</code> 이다.<br>
따라서 <code>∂y_out1 / ∂가중합3 = y_out1 * (1 - y_out1)</code> 이 된다.
2-3) <code>가중합3 = w31 * yh1 + w41 * yh2 + 1(bias)</code> 형태인데, <code>(∂가중합3 / ∂w31)</code> 식에 첫 식을 대입하면 <code>(∂가중합3 / ∂w31 = yh1</code> 이 된다.</p>
</li>
<li>
<p>(2)에서 구한 세 식을 합하면 <code>(y_out1 - y_target1) * (y_out1 * (1 - y_out1)) * (yh1)</code> 형태이다. 이때,<br>
<code>y_out1 - y_target1</code> 은 출력값, <code>y_out1 * (1 - y_out1)</code> 은 활성화함수의 미분 값이다. 이를 활용하여 델타 식으로 표현하면<br>
<code>w31(t + 1) = w31 * t - δ * y * yh1</code> 이 된다. (<code>δ * y = (y_out1 - y_target1) * (y_out1 * (1 - y_out1))</code>)</p>
</li>
</ol>
<h4 id="은닉층-오차">은닉층 오차</h4>
<ul>
<li>
<p>위에서 w31을 구했고, 이제 w11을 구해보자</p>
</li>
<li>
<p>w31은 y_out1에만 영향을 주고, y_out2에는 영향을 주지 않았다. 하지만 w11은 y_out1과 y_out2에 모두 영향을 주어서 식의 복잡도가 높다.</p>
</li>
<li>
<p>점화식을 표현하면 <code>w11(t+1) = w11 * t - (∂오차 y_out) / ∂w11</code> 가 된다.</p>
<ol>
<li><code>(∂오차 y_out) / ∂w11 = (∂오차 y_out) / ∂yh1 * (∂yh1/∂가중합1) * (∂가중합1/∂w11)</code> 형태로 chain rule을 사용할 수 있다.</li>
<li><code>(∂yh1/∂가중합1)</code> 은 activation 함수의 미분값이므로, <code>(∂yh1/∂가중합1) = yh1(1 - yh1)</code> 이 된다.</li>
<li>가중합을 w에 의해 미분하면 입력값이 된다. 따라서 <code>(∂가중합1/∂w11) = x1</code></li>
<li><code>(∂오차 y_out) / ∂yh1 = ∂(오차y_out1 + 오차y_out2)/∂yh1 = ∂오차y_out1/∂yh1 + ∂오차y_out2/∂yh1</code><br>
5-1) 4 식을 나눠서 계산해보자. 먼저  <code>∂오차y_out1/∂yh1 = ∂오차y_out1 / ∂가중합3 * ∂가중합3 / ∂yh1'   5-1-1) 이때 </code>∂가중합3 / ∂yh1 = ∂(w31 * yh1 + w32 * yh2)/∂yh1 = w31<code>5-1-2) </code>∂오차y_out1 / ∂가중합 = (∂오차y_out1 / ∂y_out1) * (∂y_out1 / ∂가중합3) = ( y_out1 - y_target1) * w31  * (1-y_out1) * y_out1<code> (</code>∂오차y_out1 / ∂y_out1<code>는 오차를 의미하고,</code>∂y_out1 / ∂가중합3<code>는 활성함수의 미분값을 의미하기 때문)   5-1-3) 최종적으로</code>∂오차y_out1 / ∂yh1 = (y_out1 - y_target1) * w31 * (1 - y_out1) * y_out1 = δy_out1 * w31<code>형태로 델타식을 만들 수 있다.   5-2)  다음</code>∂오차y_out2/∂yh1<code>도 5-1 에서 사용한 방식으로 계산하면 </code>∂오차y_out2/∂yh1 = δy_out2 * w41<code>형태가 된다.   5-3) 위 값들로 4 에서 봤던 식을 구성하면 </code>(∂오차 y_out) / ∂yh1 = δy_out1 * w31 + δy_out2 * w41` 이 된다.</li>
<li>2, 3, 5-3 에서 나온 값으로 1식을 재구성해보면 <code>(∂오차 y_out) / ∂w11 = (δy_out1 * w31 + δy_out2 * w41) * yh1(1 - yh1) * x1</code> 이다.</li>
</ol>
</li>
<li>
<p>출력층의 오차 업데이트 : <code>(y_out1 - y_target1) * y_out1 * (1 - y_out1) * yh1</code></p>
<ul>
<li><code>(y_out1 - y_target1)</code> : 오차</li>
</ul>
</li>
<li>
<p>은닉층의 오차 업데이트 : <code>(y_out1 * w31 + y_out2 * w41) * yh1 * (1-yh1) * x1</code></p>
<ul>
<li><code>(y_out1 * w31 + y_out2 * w41)</code> : hidden layer를 통해 출력값을 미분한 값</li>
</ul>
</li>
<li>
<p>&lsquo;출력층의 오차 업데이트&rsquo;와 &lsquo;은닉층의 오차 업데이트&rsquo;는 공통적으로 <code>y_out(1 - y_out) * x</code> 의 형태(sigmoid function 미분 * 입력값)를 지니고 있다.</p>
</li>
<li>
<p>은닉층의 가중치 업데이트를 델타식으로 표현하면  <code>w11(t+1) = w11 * t - δh * x1</code> 이다.</p>
</li>
<li>
<p>델타식으로 표현하면 generic 한 형태로 식을 가져갈 수 있어 꼭 필요하다.</p>
</li>
</ul>
<hr>
<h3 id="그래디언트-소실gradient-vanishing">그래디언트 소실(gradient vanishing)</h3>
<ul>
<li>다층 퍼셉트론을 사용할 때, 층이 많을 수록 데이터 분석 능력이 높아지지만, 실제로는 분석 증가량이 미미하다. 이는 활성화 함수 때문이다.
<ul>
<li>가중치를 수정할 때, 오차 값을 미분한 값을 사용하였다.</li>
<li>각 층의 activation function 으로 sigmoid를 사용했는데, sigmoid 함수는 미분시 최대치가 0.3 밖에 되지 않는다.</li>
<li>층을 지날수록 activation function을 여러번 거치는데, sigmoid의 미분값을 여러번 거치게 되면 미분값이 중간에 0이 되어버리는 현상(vanishing gradient) 문제가 발생한다.</li>
<li>층을 거쳐 갈수록 기울기가 사라져 가중치를 수정할 값이 소실되어 뒤쪽 layer는 더이상 학습이 되어지지 않는다.</li>
</ul>
</li>
<li>그래디언트 소실 문제를 해결하기 위해 sigmoid를 대체할 다른 활성화함수들이 만들어 졌다.
<ul>
<li>하이퍼볼릭 탄젠트 : 미분 최대값 1, 소실문제를 약화시킬 순 있지만 해결되진 않는다.</li>
<li>렐루 : 0미만은 미분값 0, 0이상은 미분값 1. 많은 층을 사용할 때는 relu를 많이 사용한다.</li>
<li>소프트플러스</li>
</ul>
</li>
</ul>
<h4 id="xavier와--he-초기화">xavier와  he 초기화</h4>
<ul>
<li>초기 w와 b 할당시 표준편차가 1이고, 평균이 0인 정규분포를 사용하였다.</li>
<li>이렇게 되면 node를 통과한 결과값이 0과 1에 치중되어 있는 형태를 볼 수 있다.</li>
<li>표준편차를 0.01을 주면 결과값이 0.5로 치중되게 된다. 이렇게 되면 layer를 몇개를 쓰던 layer가 하나인 경우와 동일한 효과가 나온다. 이를 표현력의 제한이라 한다.</li>
<li>이러한 문제점을 xavier 방법을 사용하면 해결할수 있다.
<ul>
<li>가중치 초기화를 설정하는 방법으로, 결과값의 분포를 더 광범위하게 설정할 수 있게 하는 방법이다.</li>
<li><code>√(2/n_in + n_out)</code> 형태로 최초 사용하는 분포를 만들게 되면 더 광범위한 형태로 만들 수 있다. (n_in : layer의 입력node 개수, n_out : layer의 출력node 개수)</li>
<li>우리는 입력,출력 값이 같은 hidden layer를 사용하므로 <code>√(1/n)</code> 형태를 가진다.</li>
</ul>
</li>
<li>단, xavier 방식은 좌우 대칭인 activation function 에서는 효과적이지만, relu와 같은 좌우 비대칭 형태의 activation function에서는 한쪽으로 치우친 결과값이 얻어진다.</li>
<li>이때는 &lsquo;카밍 히&rsquo;의 이름을 따서 he 초기값을 사용한다.
<ul>
<li><code>√2/n</code> 의 정규분포 값을 사용한다. (분포 범위를 더 넓게 잡는다)</li>
</ul>
</li>
</ul>
<hr>
<h3 id="고속-옵티마이저">고속 옵티마이저</h3>
<ul>
<li>옵티마이저란 경사하강법을 뜻한다. 고속 옵티마이저란 경사 하강법을 더 효율적으로 하는 방법이다.</li>
<li>경사 하강법은 대체로 학습 속도와 정확도 문제를 갖고 있다. (learning rate 혹은 data에 의해 발생)
<ul>
<li>경사 하강법은 업데이트 시마다 전체 데이터에 대해 미분을 계산하여야 하여 속도가 매우 느리다.</li>
<li>학습률이 너무 크면 더이상 최적값으로 수렴하지 못하는 경우가 있다.</li>
</ul>
</li>
<li>경사 하강법은 구현하기 쉽고 단순하다는 장점이 이 있지만, 비등방성 함수에서는 탐색 경로가 비효율적이다. (ex: <code>f(x,y) = 1/20x^2 + y^2</code> 와 같은 타원형 형태)
<ul>
<li>y축은 가파르지만, x축 변동은 거의 없다. 최적값은 (0,0) 이지만 미분으로 기울기 값을 구하면 (0,0) 이 아닌 다른 방향을 가리킬 확률이 매우 높다.</li>
<li>정상적으로 도달하더라도 지그재그 형태로 비효율적인 방식으로 이동하게 된다.</li>
</ul>
</li>
<li>경사 하강법은 무작정 기울어진 방향으로 진행하기 때문에 간단하지만 위와같은 문제점을 야기한다.</li>
<li>경사 하강법의 문제점을 개선해 주는 모델들로는 &lsquo;모멘텀&rsquo;, &lsquo;adagrad&rsquo;, &lsquo;adam&rsquo; 등이 있다.</li>
</ul>
<h4 id="모멘텀">모멘텀</h4>
<ul>
<li>모멘텀 알고리즘은 물리 현상의 운동량에 착안하여 만들어 졌다.</li>
<li>이전 회차의 미분값 중 일정 비율을 반영하여 현재 weight 값 설정에 영향을 주도록 하여 더 빠르게 최적점을 찾을 수 있도록 하는 방식이다.
<ul>
<li>기존에는 현재 미분값 * 학습률을 현재 w에 빼주었지만, 모멘텀에서는 (일정 비율) * (이전 미분값) - (학습률) * (현재 미분값) 을 현재 w에 더해준다.</li>
<li>이 값은 <code>V(t) = γ*v(t-1) - η*∂오차/∂w(t)</code> 로 표현한다.</li>
<li>즉, <code>W(t+1) = W(t) + V(t)</code> 와 같은 식이 된다.</li>
<li>이전의 미분값을 일부 적용함으로써 현재 미분값을 상충하는 효과를 얻을 수 있다. 이를 통해 학습 속도를 높일 수 있다.</li>
</ul>
</li>
</ul>
<h4 id="네스테로프-모멘텀">네스테로프 모멘텀</h4>
<ul>
<li>네스테로프 모멘텀에서는 w를 업데이트 할 때 <code>γ*v(t-1) - η*∂오차/∂w(t)</code> 값 대신 <code>γ*v(t-1) - η*∂오차/∂(w(t) + γ*v(t-1))</code> 를 사용한다.</li>
<li>모멘텀 방법으로 이동될 방향을 미리 예측하여 해당 방향으로 한단계 미리 이동한 그래디언트 값을 사용함으로써 불필요한 이동을 줄일 수 있다. 속도는 그대로이지만 단계를 절약할 수 있다.</li>
</ul>
<h4 id="아다그리드">아다그리드</h4>
<ul>
<li>학습률을 조절하여 효율을 높인 모멘텀이다.</li>
<li>아다그라드는 weight값이 업데이트 될 때 마다 점점 최적점을 찾아간다고 가정하고, 학습을 시킬때 마다 일정량의 learning rate를 떨어뜨린다.</li>
<li>학습률을 변화시키기 위해 G(t)값을 <code>G(t) = G(t-1) + [∂오차/∂w(t)]^2</code> 형태로 가져가며, 최종적으로 <code>W(t+1) = W(t) + η * (1/√G(t) + ε) * ∂오차/∂w(t)</code> 형태가 된다. (ε 는 0이 되는것을 방지하기 위해 더해주는 아주 작은 상수값)</li>
</ul>
<h4 id="rmsprop">RMSprop</h4>
<ul>
<li>아다그라드에서 G(t)는 무한히 커지게 되는 문제점이 있다.</li>
<li>이를 해결하기 위해 <code>G(t) = γ * G(t-1) + (1-γ) * [∂오차/∂w(t)]^2</code> 형태를 취한다.</li>
<li>&lsquo;γ&rsquo; 값을 이용해 G(t) 값을 조절할 수 있도록 하였다.</li>
</ul>
<h4 id="adam">Adam</h4>
<ul>
<li>
<p>RMSprop의 정확도, 모멘텀 방식의 속도 장점을 모두 취하는 방식이다.</p>
</li>
<li>
<p>RMSprop의 G(t) 값과 모멘텀의 V(t) 값을 유사하게 구하여 사용한다.</p>
<ul>
<li><code>V(t) = γ_1 * G(t) + (1 - γ_1) * ∂오차/∂w(t)</code></li>
<li><code>G(t) = γ_2 * G(t) + (1 - γ_2) * [∂오차/∂w(t)]^2</code></li>
</ul>
</li>
<li>
<p>V(t)와 G(t) 값을 조절하여 V&rsquo;(t), G&rsquo;(t) 를 만들어 W(t+1) 을 구한다.</p>
<ul>
<li><code>V'(t) = V(t) / (1-r_1^t)</code></li>
<li><code>G'(t) = G(t) / (1-r_2^t)</code></li>
<li><code>W(t+1) = W(t) - η * (G'(t) / √(V'(t) + ε))</code></li>
</ul>
</li>
<li>
<p>이때까지 내용을 모두 분석해 보면 전반적으로 adam 옵티마이저가 좋은 성능을 내기는 한다.</p>
</li>
<li>
<p>하지만 항상 adam이 최적의 효율을 내지는 않는다. 이는 데이터 형태가 다르기 때문이다.</p>
</li>
<li>
<p>데이터 형태에 따라 취해지는 패턴과 오차 그래프의 모양이 다르기 때문이다.</p>
</li>
<li>
<p>gradient descent, momentum, adagrid, adam, RMSprop 중 어느것이 효과가 좋은지 확인이 필요하다.</p>
</li>
</ul>
<hr>
<h3 id="다중-분류">다중 분류</h3>
<ul>
<li>입력값을 기준으로 단순 0 또는 1을 판단하는게 아니라, 여러 class 중 하나로 분류하는 모델을 알아보자</li>
<li>출력 node 개수를 분류되는 항목 개수로 설정한다.</li>
<li>활성화 함수를 적용하려면 Y값이 0과 1로 이루어져 있어야 한다. (100% 혹은 0%)
<ul>
<li>출력 node가 하나라면 Y값은 0 또는 1이면 되지만, 2개 이상이라면 배열이 되어야 한다.</li>
<li>1 =&gt; [1,0,0], 2 =&gt; [0,1,0], 3 =&gt; [0,0,1] 형태로 변형해서 사용해야 한다.</li>
<li>이렇게 Y값을 0 또는 1로만 이루어진 형태로 바꾸어주는 기법을 one-hot-encoding 이라 한다.</li>
<li>텐서플로에서 <code>one_hot()</code> 함수를 지원한다.</li>
</ul>
</li>
</ul>
<h4 id="softmax">softMax</h4>
<ul>
<li>classification 문제를 풀 때 점수 벡터를 클래스 별 확률로 변환하기 위해 사용하는 함수이다.</li>
<li>각 점수 벡터에 지수를 취한 후 정규화 상수로 나누어 총합이 1이 되도록 계산한다.
<ul>
<li>exponential을 취하는 이유는 값이 클 수록 훨씬 더 높은 점수를 갖게 하기 위함이다.</li>
<li><code>y_k = exp(a_k) / ∑&lt;i=1,n&gt; exp(a_i)</code></li>
</ul>
</li>
<li>softMax는 exponential을 사용하기 때문에 큰 값의 나눗셈을 수행해야 하여 overflow가 발생하기 쉽다.</li>
<li>수식을 개선하여 다음과 같이 사용한다. (keras에서도 개선된 수식을 사용함)</li>
</ul>
<pre><code>y_k = exp(a_k) / ∑&lt;i=1,n&gt; exp(a_i)
    = C * exp(a_k) / C * ∑&lt;i=1,n&gt; exp(a_i)
    = exp(a_k + log C) / ∑&lt;i=1,n&gt; exp(a_i + log C)
    = exp(a_k + C') / ∑&lt;i=1,n&gt; exp(a_i + C')
</code></pre><h4 id="cross-entropy">Cross Entropy</h4>
<ul>
<li>softmax 에서 사용하는 오차방정식</li>
<li>cross entrpoy는 서로 다른 두 값의 확률 차이를 나타낼 수 있다.</li>
<li><code>E = - ∑&lt;k&gt; t_k * log y_k</code> 형태를 가진다.
<ul>
<li>ex) 정답이 [0, 1] 이고, 결과가 [1, 0] 인 경우, <code>E = 0 * log1 + 1 * log0 = ∞</code></li>
<li>ex) 정답이 [0, 1] 이고, 결과가 [0, 1] 인 경우, <code>E = 1 * log1 + 0 * log0 = 0</code></li>
</ul>
</li>
</ul>
<hr>
<h3 id="오버피팅">오버피팅</h3>
<ul>
<li>훈련 데이터에 지나치게 적응하여 훈련 그 외의 데이터에 대해서는 제대로 평가를 하지 못하는 경우를 일컫는다.</li>
<li>학습 데이터를 통해 경향성만 추출해 내는 것이 가장 바람직한 학습 목표이다.</li>
<li>오버피팅은 모든 데이터를 모으지 못하면 발생할 수 있다. (훈련 데이터가 적을 때)
<ul>
<li>한쪽으로 편향된 데이터를 학습에 사용하거나, 노이즈를 일으키는 데이터를 사용한 경우에 발생할 수 있다.</li>
</ul>
</li>
<li>은닉층이 너무 많거나 각 층의 노드 수가 많아 변수가 복잡해지면 발생할 수 있다.</li>
<li>테스트 셋과 학습 셋이 중복될 때 생기기도 한다.</li>
</ul>
<h4 id="데이터-처리-방법">데이터 처리 방법</h4>
<ul>
<li>오버피팅을 줄이기 위해서 데이터를 조작하는 방법을 사용할 수 있다.</li>
</ul>
<ol>
<li>학습 데이터셋과 테스트 데이터셋을 구분해서 사용한다.</li>
</ol>
<ul>
<li>학습 : 테스트 를 7:3 또는 8:2 정도로 사용하는 것이 일반적이다.</li>
</ul>
<ol>
<li>학습 데이터를 &lsquo;학습&rsquo; 데이터와 &lsquo;검증&rsquo; 데이터로 나눈다.</li>
</ol>
<ul>
<li>학습 데이터를 이용하여 모델을 학습시킨다.</li>
<li>학습을 시키면서 중간중간 검증 데이터를 이용하여 학습된 모델을 검증한다.</li>
<li>데이터를 학습시킬수록 &lsquo;학습&rsquo; 데이터에 대한 오차는 점점 줄어들지만, &lsquo;검증&rsquo; 데이터에 대한 오차는 일정 구간이 되면 증가하게 된다.</li>
<li>&lsquo;검증&rsquo; 데이터 오차가 증가하는 시점이 over-fitting이 시작되는 구간이므로 학습을 중단한다.</li>
<li>&lsquo;검증&rsquo; 데이터는 학습에 사용되지 않고, 검증에만 사용됨에 주의한다.</li>
</ul>
<ol>
<li>Dropout 규제 방법</li>
</ol>
<ul>
<li>제프리 힌튼이 2012년에 제안한 방법</li>
<li>매 훈련 step에서 일정 node를 훈련에서 무시하는 방법이다.
ex) node = {n1, n2, n3, n4} 가 있다면, step 1에서는 n1, n2만 있는 것 처럼 동작하고, step 2에서는 n3, n4만 있는 것 처럼 동작하고 &hellip;</li>
</ul>
<ol>
<li>데이터를 증식한다.</li>
</ol>
<ul>
<li>관련 데이터를 모두 수집하는것이 최선이지만, 현실적으로 불가능하다.</li>
<li>대신 데이터를 증식하는 방법을 사용한다. 데이터 증식이란, 실제와 같은 훈련 데이터를 생성한다.
<ul>
<li>데이터 증식은 인공적으로 만든 샘플과 실제 데이터를 구분할 수 없어야 한다.</li>
<li>백색소음(white noise)를 추가하는 것은 도움이 되지 않는다. 의미있는 학습 데이터가 필요하다.</li>
</ul>
</li>
<li>데이터 증식은 이미지 데이터를 처리할 때 매우 유용하다. 이미지는 확대, 축소, 이동, 회전, 반전 등을 통해 하나의 이미지로 여러 데이터를 만들 수 있다.</li>
</ul>
<h4 id="k겹-교차-검증의-이해">K겹 교차 검증의 이해</h4>
<ul>
<li>데이터 셋을 학습용과 테스트용으로 나누었을 경우, 테스트에 사용되는 데이터는 극히 일부밖에 되지 않는다</li>
<li>데이터 셋을 k등분 하여, 테스트 셋과 학습 셋을 돌려가며 사용하는 방법을 k겹 교차검증이라 한다.
<ul>
<li>전체 데이터를 5개로 나누었다 가정하고, 나눈 데이터의 덩어리를 각각 d1, d2, d3, d4, d5라 하자</li>
<li>이때 d1을 테스트 데이터로 사용, 나머지를 훈련 데이터로 사용한 경우 결과를 R1이라 하자</li>
<li>d2를 테스트 데이터로 사용, 나머지를 훈련 데이터를 사용한 경우 결과를 R2라 하자</li>
<li>d3, d4, d5도 마찬가지로 하여 R3, R4, R5를 도출해 낸다.</li>
<li>R1~R5를 모두 합치면 최종 결과가 나온다.</li>
<li>데이터를 5등분 했으므로, 위 방법은 5겹 교차검증이 된다.</li>
</ul>
</li>
</ul>
<pre><code>from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold

import numpy
import pandas as pd
import tensorflow as tf

numpy.random.seed(777)
tf.random.set_seed(777)

df = pd.read_csv('sonar.csv', header=None)

dataset = df.values
x_data = dataset[:,0:60].astype(float)
y_data = dataset[:,60]

# y_data를 one-hot 으로 처리해 준다.

e = LabelEncoder()
e.fit(y_data)
y_data = e.transform(y_data)

# k-fold 알고리즘을 사용할 객체를 형성한다.
# n_splits : 10등분하여 사용할 것이다.
# shuffle : 섞어서 사용할 수 있도록 허용
# random_state : shuffle 사용시 사용할 랜덤한 seed 값

n_fold = 10
skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=48)

accuracy = []

# skf.split() 함수를 통해 x_data와 y_data를 k-fold 알고리즘에 맞게 분해하여 반환한다.
# for문을 통해 데이터를 반복하여 학습을 수행한다.
for train, test in skf.split(x_data, y_data):
    # 모델을 구성한다.
    # 활성함수로 sigmoid, 오차함수로 binary-binary_crossentropy를 사용할 것이다.
    model = Sequential()
    model.add(Dense(30, input_dim=60, activation='relu'))
    model.add(Dense(10, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(loss='binary_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])
    model.fit(x_data[train], y_data[train], epochs=100, batch_size=5)
    k_accuracy = &quot;%.3f&quot; % (model.evaluate(x_data[test], y_data[test])[1])
    accuracy.append(k_accuracy)

print(&quot;\n %.f fold accuracy:&quot; % n_fold, accuracy)
# 결과값은 데이터에 따라 달라질 수 있다. 학습에 사용된 데이터가 편향되어 있는 경우 평가 결과가 떨어지는 모습을 볼 수 있다.
# k-fold 알고리즘을 사용하면 이러한 경우를 예방할 수 있다.
</code></pre><h2 id="모델">모델</h2>
<ul>
<li>딥 러닝을 위한 신경망 구조를 모델이라 한다</li>
</ul>
<h3 id="모델-정의-방법과-최적화">모델 정의 방법과 최적화</h3>
<ul>
<li>x 데이터는 attribute, y 데이터는 class라 칭한다.</li>
</ul>
<ol>
<li>입력층, 은닉층, 출력층 구성</li>
</ol>
<ul>
<li>아래 내용들은 일반적인 경우에 해당하는 경우이므로, 실제 모델 정의시에는 직접 확인해볼 필요가 있다.</li>
</ul>
<ol>
<li>데이터에 맞게 입력층의 node 개수를 결정한다.</li>
<li>얕은 신경망보다 심층 신경망이 효율적인 파라미터를 구성한다. (하나씩 layer를 늘려가 본다.)</li>
<li>은닉층의 노드 개수를 입력 노드 개수보다 많이 편성한다. (무조건은 아니므로 확인 필요)</li>
<li>결정할 수 있는 데이터를 조금씩 줄여 깔때기 모양으로 은닉층을 설정하는게 좋다. (갈수록 node 개수를 줄여감)</li>
<li>첫 은닉층의 노드 개수는 과대적합(over fitting)이 시작되기 전까지 뉴런 수를 점진적으로 늘리는 것이 좋다.</li>
<li>은닉층이 많아질수록 ReLU 함수를 사용하는것이 좋다.(vanishing 현상 방지)</li>
<li>출력층의 활성화 함수를 결정하고, 출력층의 활성화 함수에 따라 오차함수도 결정한다.</li>
</ol>
<ul>
<li>둘중 하나를 선택한다면 sigmoid 함수와 binary_crossentropy 를 사용한다.</li>
</ul>
<ol>
<li>다중분류 모델링</li>
</ol>
<ol>
<li>데이터의 속성에 맞게 입력 node의 수 구성</li>
<li>문자열로 된 class 값을 indexing 하고, one-hot-encoding으로 값을 변형해준다.</li>
<li>class의 개수에 맞게 출력층 node 개수를 설정한다.</li>
<li>활성화 함수 및 오차방정식으로 softMax와 categorical cross-entropy를 적용한다.</li>
</ol>
<h3 id="생성-방법">생성 방법</h3>
<ol>
<li>tensorflow.keras.Sequential : Sequential 함수를 이용하는 방법</li>
<li>functional approach : 직접 함수를 구성하는 방법</li>
<li>tensorflow.keras.Model : Model 클래스를 상속하고 재정의하여 사용하는 방법</li>
</ol>
<h4 id="kerassequential">Keras.Sequential</h4>
<ul>
<li>keras를 이용해서 sequential 모델을 생성하는 방법</li>
<li><code>model = Sequential()</code> : sequential 한 layer 형태를 가진 모델을 생성</li>
<li><code>model.add(Dense(units =2, activation='sigmoid', input_dim = 2))</code> : layer 추가
<ul>
<li>node 수가 2개</li>
<li>activation function이 sigmoid</li>
<li>입력값이 2차원 형태</li>
<li>input 인자는 첫번 째 hidden layer에만 사용해 주면 된다.</li>
</ul>
</li>
<li><code>model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])</code> : model 객체를 어떤 형태로 학습시킬지 정의
<ul>
<li>binary_crossentropy 를 loss function으로 설정</li>
<li>optimizer로 sdz 설정</li>
<li>실행될 때 마다 loss 값과 accuracy 값을 출력으로 보여줌</li>
</ul>
</li>
<li><code>model.fit(x_train, y_train, epochs=50000, batch_size = 10)</code> : model에 training 실행
<ul>
<li>x_train, y_train : 학습용 x, y 데이터</li>
<li>epochs : 학습 데이터를 통해 반복 학습시킬 횟수</li>
<li>batch_size : 입력 데이터를 몇 묶음 단위로 전달할지 설정, 하나씩 학습하는 것 보다 학습률 출렁임이 더 안정적이다.</li>
</ul>
</li>
<li><code>model.layers[0].get_weights()[0]</code> :
<ul>
<li>model.layers 는 입력 layer을 0번째 index로 하여 특정 layer를 반환</li>
<li>get_weights() 는 해당 layer의 [weight, bias] 를 담고 있는 배열을 반환</li>
</ul>
</li>
<li><code>model.predict(x_predict)</code> : 학습된 모델에 x_predict 값을 넣을 시 특정 y 값을 추정하여 반환하는 함수</li>
<li><code>model.evaluate(x_data, y_data)</code> : 학습된 모델에 입력값(x_data)과 정답(y_data) 를 전달받아 [loss, accuracy] 를 반환하는 함수</li>
</ul>
</article><section class="article labels"><a class="category" href=/categories/dev/>dev</a><a class="tag" href=/tags/tensorflow/>tensorflow</a><a class="tag" href=/tags/deep-learning/>deep learning</a><a class="tag" href=/tags/python/>python</a></section><section class="article author"><img class="avatar" src="https://d33wubrfki0l68.cloudfront.net/ddf49425628d8aec7523db143916b34ae1641e11/b97e8/images/gopher-side_color.svg" alt><p class="name">gohugo</p><div class="bio">Hugo is one of the most popular open-source static site generators. With its amazing speed and flexibility, Hugo makes building websites fun again.</div><div class="details"><a class="item" href="https://github.com/gohugoio" target="_blank"><span class="iconfont icon-github"></span>&nbsp;gohugoio</a><a class="item" href="https://twitter.com/GoHugoIO" target="_blank"><span class="iconfont icon-twitter"></span>&nbsp;@GoHugoIO</a></div>
</section></div>
<div class="article bottom"><section class="article navigation"><p><a class="link" href="/post/golang/"><span class="li iconfont icon-article"></span>Golang</a></p><p><a class="link" href="/post/kivy/"><span class="li iconfont icon-article"></span>Kivy</a></p></section></div></section><section id="footer"><div class="footer-wrap">
    <p class="copyright">©2020 Notepadium.</p>
    <p class="powerby"><span>Powered by </span><a href="https://gohugo.io" 
        target="_blank">Hugo</a><span> and the </span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank">Notepadium</a></p>
</div></section></body>

</html>